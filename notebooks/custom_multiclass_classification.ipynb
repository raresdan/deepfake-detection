{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1yDbUZfAZaGwc5t3I4jTmqnvAl_PrUCYI","authorship_tag":"ABX9TyNBjNlNbZKGuNw1BY7E+rfi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqgBxo1swgu1","executionInfo":{"status":"ok","timestamp":1749687341097,"user_tz":-180,"elapsed":22347,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"dd05b5e8-1b29-43ea-8369-c53382cd2e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install mlflow torch torchvision timm --quiet"],"metadata":{"id":"PVnt8TBr_kOg","executionInfo":{"status":"ok","timestamp":1749687437633,"user_tz":-180,"elapsed":96552,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc46b168-4715-446d-9f25-d50b132b2dc2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.7/733.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import mlflow\n","\n","MLFLOW_DIR = \"/content/drive/MyDrive/deepfake-detection/runs\"\n","mlflow.set_tracking_uri(f\"file:{MLFLOW_DIR}\")"],"metadata":{"id":"cr0VmQjM_qJ_","executionInfo":{"status":"ok","timestamp":1749687439877,"user_tz":-180,"elapsed":2249,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import mlflow\n","import mlflow.pytorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, recall_score, precision_score\n","import numpy as np\n","from PIL import Image\n","import random\n","import timm\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"IoWSPnb8_9wG","executionInfo":{"status":"ok","timestamp":1749687504573,"user_tz":-180,"elapsed":11140,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# MLFlow Setup\n"],"metadata":{"id":"cHIonqixASE2"}},{"cell_type":"code","source":["config = {\n","    \"experiment_name\": \"custom_deepfake_multiclass_large_random\",\n","    \"model_name\": \"custom\",\n","    \"data_path\": \"/content/drive/MyDrive/deepfake-detection/datasets/large_dataset_random\",\n","    \"batch_size\": 32,\n","    \"num_epochs\": 10,\n","    \"learning_rate\": 1e-4,\n","    \"img_height\": 218,\n","    \"img_width\": 178,\n","    \"dropout\": 0.2,\n","    \"optimizer\": \"adam\",\n","    \"loss_fn\": \"crossentropy\",\n","    \"random_seed\": 42\n","}"],"metadata":{"id":"LNPA-TcA__o9","executionInfo":{"status":"ok","timestamp":1749687504575,"user_tz":-180,"elapsed":10,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["mlflow.set_tracking_uri(\"file:/content/drive/MyDrive/deepfake-detection/runs\")\n","mlflow.set_experiment(config[\"experiment_name\"])"],"metadata":{"id":"NmPbTXI6AKVM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749687504660,"user_tz":-180,"elapsed":88,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"afc47f01-3751-4ad1-bbf6-7e9e2055a18d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='file:///content/drive/MyDrive/deepfake-detection/runs/993973592097192765', creation_time=1749687457511, experiment_id='993973592097192765', last_update_time=1749687457511, lifecycle_stage='active', name='custom_deepfake_multiclass_large_random', tags={}>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Data Preparation"],"metadata":{"id":"qaVK2o79AUKQ"}},{"cell_type":"code","source":["def compute_fft_channel(img):\n","    # img: [H,W,3], numpy, range [0,255]\n","    gray = np.mean(img, axis=2)\n","    fft = np.abs(np.fft.fft2(gray))\n","    fft = np.fft.fftshift(fft)\n","    fft = np.log(fft + 1)\n","    fft = (fft - fft.min()) / (fft.max() - fft.min() + 1e-8)\n","    return fft.astype(np.float32)"],"metadata":{"id":"xubG4uuMdq_Y","executionInfo":{"status":"ok","timestamp":1749687504675,"user_tz":-180,"elapsed":13,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class MultiClassDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, real_fraction=0.2, real_class_name=\"real\", seed=42):\n","        self.samples = []\n","        self.transform = transform\n","        self.class_to_idx = {}\n","        self.idx_to_class = {}\n","\n","        subdirs = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n","        for idx, subdir in enumerate(subdirs):\n","            self.class_to_idx[subdir] = idx\n","            self.idx_to_class[idx] = subdir\n","\n","        rng = random.Random(seed)\n","        for subdir in subdirs:\n","            subdir_path = os.path.join(root_dir, subdir)\n","            label = self.class_to_idx[subdir]\n","            images = [\n","                os.path.join(subdir_path, fname)\n","                for fname in os.listdir(subdir_path)\n","                if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n","            ]\n","            if subdir.lower() == real_class_name.lower() and real_fraction < 1.0:\n","                n_keep = max(1, int(len(images) * real_fraction))\n","                images = rng.sample(images, n_keep)\n","            self.samples.extend((img_path, label) for img_path in images)\n","        self.num_classes = len(self.class_to_idx)\n","        self.total_images = len(self.samples)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label = self.samples[idx]\n","        img = Image.open(path).convert(\"RGB\").resize((224,224))\n","        img_np = np.array(img).astype(np.float32) / 255.0\n","        fft_channel = compute_fft_channel((img_np * 255).astype(np.uint8))\n","        img_4ch = np.concatenate([img_np.transpose(2,0,1), fft_channel[None]], axis=0)\n","        return torch.tensor(img_4ch, dtype=torch.float32), int(label)"],"metadata":{"id":"yBsGVpIJE4_l","executionInfo":{"status":"ok","timestamp":1749687504691,"user_tz":-180,"elapsed":15,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(config[\"random_seed\"])\n","\n","transform = transforms.Compose([\n","    transforms.Resize((config[\"img_height\"], config[\"img_width\"])),\n","    transforms.ToTensor()\n","])\n","\n","dataset = MultiClassDataset(config[\"data_path\"], transform=transform)\n","\n","total_size = len(dataset)\n","train_size = int(0.7 * total_size)\n","val_size = int(0.15 * total_size)\n","test_size = total_size - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(\n","    dataset, [train_size, val_size, test_size],\n","    generator=torch.Generator().manual_seed(config[\"random_seed\"])\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)"],"metadata":{"id":"Kl-GKqpNAQg_","executionInfo":{"status":"ok","timestamp":1749687518246,"user_tz":-180,"elapsed":13553,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Model Definition"],"metadata":{"id":"GrphgVCxAnIO"}},{"cell_type":"code","source":["class SEBlock(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.fc1 = nn.Linear(channels, channels // reduction)\n","        self.fc2 = nn.Linear(channels // reduction, channels)\n","    def forward(self, x):\n","        w = x.mean(dim=(2,3))\n","        w = F.relu(self.fc1(w))\n","        w = torch.sigmoid(self.fc2(w)).unsqueeze(-1).unsqueeze(-1)\n","        return x * w\n","\n","class DeepfakeNet(nn.Module):\n","    def __init__(self, in_channels=4, num_classes=5):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.se1 = SEBlock(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.se2 = SEBlock(64)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.attention_head = nn.Conv2d(128, 1, 1)\n","        self.fc1 = nn.Linear(128 * 28 * 28, 128)\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.se1(self.bn1(self.conv1(x)))))\n","        x = self.pool(F.relu(self.se2(self.bn2(self.conv2(x)))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        attn_map = torch.sigmoid(self.attention_head(x))\n","        x_flat = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x_flat))\n","        logits = self.fc2(x)\n","        return logits, attn_map\n"],"metadata":{"id":"f6r--haGAmWs","executionInfo":{"status":"ok","timestamp":1749687518269,"user_tz":-180,"elapsed":17,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, loader, optimizer, loss_fn, device):\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    all_labels, all_outputs = [], []\n","    for images, labels in loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits, _ = model(images)\n","        loss = loss_fn(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * images.size(0)\n","        preds = logits.argmax(dim=1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","        all_labels.extend(labels.cpu().numpy())\n","        all_outputs.extend(logits.detach().cpu().numpy())\n","    acc = correct / total\n","    avg_loss = running_loss / total\n","    return avg_loss, acc, np.array(all_labels), np.array(all_outputs)"],"metadata":{"id":"ggVxLgn_ArXu","executionInfo":{"status":"ok","timestamp":1749687959514,"user_tz":-180,"elapsed":24,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, loader, loss_fn, device):\n","    model.eval()\n","    running_loss, correct, total = 0.0, 0, 0\n","    all_labels, all_outputs = [], []\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            logits, _ = model(images)\n","            loss = loss_fn(logits, labels)\n","            running_loss += loss.item() * images.size(0)\n","            preds = logits.argmax(dim=1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_outputs.extend(logits.cpu().numpy())\n","    acc = correct / total\n","    avg_loss = running_loss / total\n","    return avg_loss, acc, np.array(all_labels), np.array(all_outputs)"],"metadata":{"id":"4i4-lYpHDyHv","executionInfo":{"status":"ok","timestamp":1749687959690,"user_tz":-180,"elapsed":3,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def plot_and_log_curve(train_values, val_values, ylabel, fname):\n","    import matplotlib.pyplot as plt\n","    plt.figure()\n","    plt.plot(train_values, label='Train')\n","    plt.plot(val_values, label='Validation')\n","    plt.xlabel('Epoch')\n","    plt.ylabel(ylabel)\n","    plt.title(f'{ylabel} Curve')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(fname)\n","    mlflow.log_artifact(fname)\n","    plt.close()"],"metadata":{"id":"o8eQlER1Hfsa","executionInfo":{"status":"ok","timestamp":1749687959942,"user_tz":-180,"elapsed":3,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def plot_and_log_confusion_matrix(y_true, y_pred, step, label=\"val\"):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(4,4))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    plt.title(f\"{label.capitalize()} Confusion Matrix\")\n","    fname = f\"{label}_confusion_matrix_{step}.png\"\n","    plt.savefig(fname)\n","    mlflow.log_artifact(fname)\n","    plt.close()"],"metadata":{"id":"vyud0YHTA2bR","executionInfo":{"status":"ok","timestamp":1749687960096,"user_tz":-180,"elapsed":15,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import numpy as np\n","import warnings\n","from sklearn.exceptions import UndefinedMetricWarning\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DeepfakeNet().to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","if config[\"optimizer\"].lower() == \"adagrad\":\n","    optimizer = optim.Adagrad(model.parameters(), lr=config[\"learning_rate\"])\n","else:\n","    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","best_val_f1 = 0\n","best_model_path = \"/tmp/best_custom.pth\"\n","\n","with mlflow.start_run():\n","    mlflow.log_params(config)\n","\n","    train_loss_list, train_acc_list = [], []\n","    val_loss_list, val_acc_list = [], []\n","\n","    for epoch in range(config[\"num_epochs\"]):\n","        train_loss, train_acc, train_labels, train_outputs = train_one_epoch(\n","            model, train_loader, optimizer, loss_fn, device)\n","        val_loss, val_acc, val_labels, val_outputs = evaluate(\n","            model, val_loader, loss_fn, device)\n","        val_labels = np.array(val_labels).astype(int).flatten()\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","        val_preds = np.argmax(val_outputs, axis=1)\n","        val_preds = np.array(val_preds).astype(int).flatten()\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n","            if len(np.unique(val_labels)) < 2:\n","                val_f1 = 0.0\n","                val_tpr = 0.0\n","                val_fpr = 0.0\n","                val_auc = float('nan')\n","            else:\n","                val_f1 = f1_score(val_labels, val_preds, average=\"macro\", zero_division=0)\n","                val_tpr = recall_score(val_labels, val_preds, average=\"macro\", zero_division=0)\n","                val_fpr = 1 - precision_score(val_labels, val_preds, average=\"macro\", zero_division=0)\n","                try:\n","                    val_auc = roc_auc_score(val_labels, val_outputs)\n","                except:\n","                    val_auc = float('nan')\n","\n","        mlflow.log_metrics({\n","            \"train_loss\": train_loss, \"train_acc\": train_acc,\n","            \"val_loss\": val_loss, \"val_acc\": val_acc,\n","            \"val_f1\": val_f1, \"val_tpr\": val_tpr, \"val_auc\": val_auc,\n","        }, step=epoch)\n","\n","        print(f\"Epoch {epoch+1}/{config['num_epochs']}: \"\n","              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n","              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, \"\n","              f\"val_f1={val_f1:.4f}, val_auc={val_auc:.4f}\")\n","\n","        if val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            torch.save(model.state_dict(), best_model_path)\n","            mlflow.log_artifact(best_model_path)\n","\n","    plot_and_log_curve(train_loss_list, val_loss_list, \"Loss\", \"loss_curve.png\")\n","    plot_and_log_curve(train_acc_list, val_acc_list, \"Accuracy\", \"accuracy_curve.png\")\n","\n","    # Save the full model for reproducibility (architecture + weights)\n","    final_model_path = \"/tmp/final_model\"\n","    mlflow.pytorch.save_model(model, final_model_path)\n","    mlflow.log_artifacts(final_model_path, artifact_path=\"final_model\")\n","    shutil.rmtree(final_model_path)\n","\n","    print(\"Training finished. Best validation F1:\", best_val_f1)\n","    plot_and_log_confusion_matrix(val_labels, val_preds, step=\"final\", label=\"val\")\n"],"metadata":{"id":"ZP4682bJDz77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749690346258,"user_tz":-180,"elapsed":2386041,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"e7d6fc3d-d178-4f24-b201-faccc97ec6f4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10: train_loss=0.8741, train_acc=0.6580, val_loss=0.6428, val_acc=0.7293, val_f1=0.7249, val_auc=nan\n","Epoch 2/10: train_loss=0.4237, train_acc=0.8229, val_loss=0.6143, val_acc=0.7373, val_f1=0.7189, val_auc=nan\n","Epoch 3/10: train_loss=0.3174, train_acc=0.8786, val_loss=0.3809, val_acc=0.8493, val_f1=0.8507, val_auc=nan\n","Epoch 4/10: train_loss=0.2100, train_acc=0.9346, val_loss=0.3596, val_acc=0.8507, val_f1=0.8547, val_auc=nan\n","Epoch 5/10: train_loss=0.1556, train_acc=0.9574, val_loss=0.3408, val_acc=0.8573, val_f1=0.8622, val_auc=nan\n","Epoch 6/10: train_loss=0.1068, train_acc=0.9766, val_loss=0.3371, val_acc=0.8547, val_f1=0.8584, val_auc=nan\n","Epoch 7/10: train_loss=0.0768, train_acc=0.9851, val_loss=0.3926, val_acc=0.8600, val_f1=0.8603, val_auc=nan\n","Epoch 8/10: train_loss=0.0611, train_acc=0.9914, val_loss=0.3571, val_acc=0.8653, val_f1=0.8665, val_auc=nan\n","Epoch 9/10: train_loss=0.0615, train_acc=0.9860, val_loss=0.3477, val_acc=0.8800, val_f1=0.8802, val_auc=nan\n","Epoch 10/10: train_loss=0.0293, train_acc=0.9986, val_loss=0.3737, val_acc=0.8627, val_f1=0.8666, val_auc=nan\n"]},{"output_type":"stream","name":"stderr","text":["2025/06/12 01:05:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2025/06/12 01:05:45 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"output_type":"stream","name":"stdout","text":["Training finished. Best validation F1: 0.8802312383288605\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(best_model_path))\n","model.eval()\n","\n","test_labels, test_outputs = [], []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        logits, attn_map = model(images)  # <-- Unpack!\n","        test_outputs.extend(logits.cpu().numpy())\n","        test_labels.extend(labels.cpu().numpy())\n","\n","test_labels = np.array(test_labels).astype(int)\n","test_outputs = np.array(test_outputs)\n","test_preds = np.argmax(test_outputs, axis=1)\n"],"metadata":{"id":"_cN7ay5iJckM","executionInfo":{"status":"ok","timestamp":1749690574787,"user_tz":-180,"elapsed":167583,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n","\n","# test_labels: shape (N,) integers; test_preds: shape (N,) integers; test_outputs: shape (N, num_classes) logits or probs\n","\n","test_f1 = f1_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n","test_recall = recall_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n","test_precision = precision_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n","\n","# For multiclass AUC, one-hot encode labels\n","import numpy as np\n","num_classes = np.max(test_labels) + 1\n","test_labels_onehot = np.eye(num_classes)[test_labels]\n","\n","try:\n","    test_auc = roc_auc_score(test_labels_onehot, np.array(test_outputs), multi_class=\"ovr\")\n","except Exception as e:\n","    test_auc = float('nan')\n","\n","print(f\"Test F1: {test_f1:.4f}, Test Recall: {test_recall:.4f}, Test Precision: {test_precision:.4f}, Test AUC: {test_auc:.4f}\")\n"],"metadata":{"id":"JRsFpmEwQaFW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749690574805,"user_tz":-180,"elapsed":11,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"de49d0b2-2a70-4a6e-82e3-4d3320b16705"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Test F1: 0.8937, Test Recall: 0.8956, Test Precision: 0.8948, Test AUC: 0.9607\n"]}]},{"cell_type":"code","source":["mlflow.log_metrics({\n","    \"test_f1\": test_f1,\n","    \"test_recall\": test_recall,\n","    \"test_precision\": test_precision,\n","    \"test_auc\": test_auc\n","})\n","\n","\n","plot_and_log_confusion_matrix(test_labels, test_preds, step=\"final\", label=\"test\")"],"metadata":{"id":"aYyEx8w1Qe_R","executionInfo":{"status":"ok","timestamp":1749690575311,"user_tz":-180,"elapsed":508,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Get the classes and their values from the model\n","classes = dataset.idx_to_class\n","class_values = list(classes.values())\n","classes, class_values"],"metadata":{"id":"bpar3rRHBwea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749690575324,"user_tz":-180,"elapsed":10,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"ed55019d-f6dc-4f2b-925e-ab8763065d5a"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({0: 'real',\n","  1: 'stable_diffusion_xl',\n","  2: 'stylegan1',\n","  3: 'stylegan2',\n","  4: 'thispersondoesnotexist'},\n"," ['real',\n","  'stable_diffusion_xl',\n","  'stylegan1',\n","  'stylegan2',\n","  'thispersondoesnotexist'])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"wiVAtIXgS9dX","executionInfo":{"status":"aborted","timestamp":1749687518540,"user_tz":-180,"elapsed":20223,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}}},"execution_count":null,"outputs":[]}]}