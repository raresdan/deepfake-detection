{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1yDbUZfAZaGwc5t3I4jTmqnvAl_PrUCYI","authorship_tag":"ABX9TyOmoIse7hCaCZdhl3K52XC/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ca479e0f9c22479fb101cc8569284566":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cae9f2f86674f65a535aead992d6042","IPY_MODEL_0fb6e627d8be4daf905a8ee252c7f49d","IPY_MODEL_f5a92348f9d745cfaa29fd8b04b205d3"],"layout":"IPY_MODEL_8d5292ac1f2a4735b44324a34d603936"}},"3cae9f2f86674f65a535aead992d6042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1574937e080a45fc94302511db605ba7","placeholder":"​","style":"IPY_MODEL_a3b0358dd1854de29b32f8315a5767b3","value":"model.safetensors: 100%"}},"0fb6e627d8be4daf905a8ee252c7f49d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaaf945c843648c2911c6f8e728f77c9","max":102469840,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c00104363a1455d952c5b2357624ea0","value":102469840}},"f5a92348f9d745cfaa29fd8b04b205d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfa7ac6690784c919ecacf2da7d551df","placeholder":"​","style":"IPY_MODEL_fe9d42b5b13841249b6417b1d6646cfe","value":" 102M/102M [00:00&lt;00:00, 179MB/s]"}},"8d5292ac1f2a4735b44324a34d603936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1574937e080a45fc94302511db605ba7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b0358dd1854de29b32f8315a5767b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaaf945c843648c2911c6f8e728f77c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c00104363a1455d952c5b2357624ea0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfa7ac6690784c919ecacf2da7d551df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe9d42b5b13841249b6417b1d6646cfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqgBxo1swgu1","executionInfo":{"status":"ok","timestamp":1748884048986,"user_tz":-180,"elapsed":40129,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"1b8de280-3d28-4371-9c95-7c3c079eafa5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install mlflow torch torchvision timm --quiet"],"metadata":{"id":"PVnt8TBr_kOg","executionInfo":{"status":"ok","timestamp":1748884167510,"user_tz":-180,"elapsed":118514,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"09a496bb-7594-45e9-c0cc-9aedc2a32d5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.9/722.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import mlflow\n","\n","MLFLOW_DIR = \"/content/drive/MyDrive/deepfake-detection/runs\"\n","mlflow.set_tracking_uri(f\"file:{MLFLOW_DIR}\")"],"metadata":{"id":"cr0VmQjM_qJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import mlflow\n","import mlflow.pytorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, recall_score, precision_score\n","import numpy as np\n","from PIL import Image\n","import random\n","import timm\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"IoWSPnb8_9wG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MLFlow Setup\n"],"metadata":{"id":"cHIonqixASE2"}},{"cell_type":"code","source":["config = {\n","    \"experiment_name\": \"resnet_deepfake_binary_large_random\",\n","    \"model_name\": \"resnet_custom\",\n","    \"data_path\": \"/content/drive/MyDrive/deepfake-detection/datasets/large_dataset_random\",\n","    \"batch_size\": 32,\n","    \"num_epochs\": 12,\n","    \"learning_rate\": 1e-4,\n","    \"img_height\": 218,\n","    \"img_width\": 178,\n","    \"dropout\": 0.8,\n","    \"optimizer\": \"adagrad\",\n","    \"loss_fn\": \"bcewithlogits\",\n","    \"random_seed\": 42\n","}"],"metadata":{"id":"LNPA-TcA__o9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlflow.set_tracking_uri(\"file:/content/drive/MyDrive/deepfake-detection/runs\")\n","mlflow.set_experiment(config[\"experiment_name\"])"],"metadata":{"id":"NmPbTXI6AKVM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748884204087,"user_tz":-180,"elapsed":4740,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"3bb51575-143c-45de-a2c4-2c0d7893b496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025/06/02 17:10:04 INFO mlflow.tracking.fluent: Experiment with name 'resnet_deepfake_binary_large_random' does not exist. Creating a new experiment.\n"]},{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='file:///content/drive/MyDrive/deepfake-detection/runs/987411805577788173', creation_time=1748884204366, experiment_id='987411805577788173', last_update_time=1748884204366, lifecycle_stage='active', name='resnet_deepfake_binary_large_random', tags={}>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Data Preparation"],"metadata":{"id":"qaVK2o79AUKQ"}},{"cell_type":"code","source":["class RealVsFakeDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.samples = []\n","        self.transform = transform\n","        for subdir in os.listdir(root_dir):\n","            subdir_path = os.path.join(root_dir, subdir)\n","            if not os.path.isdir(subdir_path):\n","                continue\n","            label = 0 if subdir.lower() == \"real\" else 1\n","            for fname in os.listdir(subdir_path):\n","                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                    self.samples.append((os.path.join(subdir_path, fname), label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label = self.samples[idx]\n","        image = Image.open(path).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n"],"metadata":{"id":"yBsGVpIJE4_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(config[\"random_seed\"])\n","\n","transform = transforms.Compose([\n","    transforms.Resize((config[\"img_height\"], config[\"img_width\"])),\n","    transforms.ToTensor()\n","])\n","\n","dataset = RealVsFakeDataset(config[\"data_path\"], transform=transform)\n","\n","total_size = len(dataset)\n","train_size = int(0.7 * total_size)\n","val_size = int(0.15 * total_size)\n","test_size = total_size - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(\n","    dataset, [train_size, val_size, test_size],\n","    generator=torch.Generator().manual_seed(config[\"random_seed\"])\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)"],"metadata":{"id":"Kl-GKqpNAQg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Definition"],"metadata":{"id":"GrphgVCxAnIO"}},{"cell_type":"code","source":["class ResNetCustom(nn.Module):\n","    def __init__(self, dropout=0.8, model_name='resnet50'):\n","        super().__init__()\n","        self.backbone = timm.create_model(model_name, pretrained=True)\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False  # Freeze backbone\n","        in_features = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Identity()\n","        self.head = nn.Sequential(\n","            nn.Linear(in_features, 2048),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(2048, 2048),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(2048, 1)\n","        )\n","    def forward(self, x):\n","        feats = self.backbone(x)\n","        out = self.head(feats)\n","        return out.squeeze(1)\n"],"metadata":{"id":"f6r--haGAmWs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNetCustom(dropout=config[\"dropout\"])"],"metadata":{"id":"Dl6odEqhDn7j","executionInfo":{"status":"ok","timestamp":1748884222862,"user_tz":-180,"elapsed":1980,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"colab":{"base_uri":"https://localhost:8080/","height":160,"referenced_widgets":["ca479e0f9c22479fb101cc8569284566","3cae9f2f86674f65a535aead992d6042","0fb6e627d8be4daf905a8ee252c7f49d","f5a92348f9d745cfaa29fd8b04b205d3","8d5292ac1f2a4735b44324a34d603936","1574937e080a45fc94302511db605ba7","a3b0358dd1854de29b32f8315a5767b3","eaaf945c843648c2911c6f8e728f77c9","3c00104363a1455d952c5b2357624ea0","cfa7ac6690784c919ecacf2da7d551df","fe9d42b5b13841249b6417b1d6646cfe"]},"outputId":"21ede6c4-e889-4b42-ec6b-c8e2054928a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca479e0f9c22479fb101cc8569284566"}},"metadata":{}}]},{"cell_type":"code","source":["def train_one_epoch(model, loader, optimizer, loss_fn, device):\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    all_labels, all_outputs = [], []\n","    for images, labels in loader:\n","        images, labels = images.to(device), labels.float().to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * images.size(0)\n","        preds = torch.sigmoid(outputs) > 0.5\n","        correct += (preds == labels.bool()).sum().item()\n","        total += labels.size(0)\n","        all_labels.extend(labels.cpu().numpy())\n","        all_outputs.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n","    acc = correct / total\n","    avg_loss = running_loss / total\n","    return avg_loss, acc, np.array(all_labels), np.array(all_outputs)"],"metadata":{"id":"ggVxLgn_ArXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, loader, loss_fn, device):\n","    model.eval()\n","    running_loss, correct, total = 0.0, 0, 0\n","    all_labels, all_outputs = [], []\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.float().to(device)\n","            outputs = model(images)\n","            loss = loss_fn(outputs, labels)\n","            running_loss += loss.item() * images.size(0)\n","            preds = torch.sigmoid(outputs) > 0.5\n","            correct += (preds == labels.bool()).sum().item()\n","            total += labels.size(0)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_outputs.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n","    acc = correct / total\n","    avg_loss = running_loss / total\n","    return avg_loss, acc, np.array(all_labels), np.array(all_outputs)"],"metadata":{"id":"4i4-lYpHDyHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_and_log_curve(train_values, val_values, ylabel, fname):\n","    import matplotlib.pyplot as plt\n","    plt.figure()\n","    plt.plot(train_values, label='Train')\n","    plt.plot(val_values, label='Validation')\n","    plt.xlabel('Epoch')\n","    plt.ylabel(ylabel)\n","    plt.title(f'{ylabel} Curve')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(fname)\n","    mlflow.log_artifact(fname)\n","    plt.close()"],"metadata":{"id":"o8eQlER1Hfsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_and_log_confusion_matrix(y_true, y_pred, step, label=\"val\"):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(4,4))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    plt.title(f\"{label.capitalize()} Confusion Matrix\")\n","    fname = f\"{label}_confusion_matrix_{step}.png\"\n","    plt.savefig(fname)\n","    mlflow.log_artifact(fname)\n","    plt.close()"],"metadata":{"id":"vyud0YHTA2bR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import numpy as np\n","import warnings\n","from sklearn.exceptions import UndefinedMetricWarning\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNetCustom(dropout=config[\"dropout\"]).to(device)\n","loss_fn = nn.BCEWithLogitsLoss()\n","\n","if config[\"optimizer\"].lower() == \"adagrad\":\n","    optimizer = optim.Adagrad(model.parameters(), lr=config[\"learning_rate\"])\n","else:\n","    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","best_val_f1 = 0\n","best_model_path = \"/tmp/best_resnet.pth\"\n","\n","with mlflow.start_run():\n","    mlflow.log_params(config)\n","\n","    train_loss_list, train_acc_list = [], []\n","    val_loss_list, val_acc_list = [], []\n","\n","    for epoch in range(config[\"num_epochs\"]):\n","        train_loss, train_acc, train_labels, train_outputs = train_one_epoch(\n","            model, train_loader, optimizer, loss_fn, device)\n","        val_loss, val_acc, val_labels, val_outputs = evaluate(\n","            model, val_loader, loss_fn, device)\n","        val_labels = np.array(val_labels).astype(int).flatten()\n","\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","\n","        val_preds = (val_outputs > 0.5).astype(int)\n","        val_preds = np.array(val_preds).astype(int).flatten()\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n","            if len(np.unique(val_labels)) < 2:\n","                val_f1 = 0.0\n","                val_tpr = 0.0\n","                val_fpr = 0.0\n","                val_auc = float('nan')\n","            else:\n","                val_f1 = f1_score(val_labels, val_preds, zero_division=0)\n","                val_tpr = recall_score(val_labels, val_preds, zero_division=0)\n","                val_fpr = 1 - precision_score(1-val_labels, 1-val_preds, zero_division=0)\n","                try:\n","                    val_auc = roc_auc_score(val_labels, val_outputs)\n","                except:\n","                    val_auc = float('nan')\n","\n","        mlflow.log_metrics({\n","            \"train_loss\": train_loss, \"train_acc\": train_acc,\n","            \"val_loss\": val_loss, \"val_acc\": val_acc,\n","            \"val_f1\": val_f1, \"val_tpr\": val_tpr, \"val_auc\": val_auc,\n","        }, step=epoch)\n","\n","        print(f\"Epoch {epoch+1}/{config['num_epochs']}: \"\n","              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n","              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, \"\n","              f\"val_f1={val_f1:.4f}, val_auc={val_auc:.4f}\")\n","\n","        if val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            torch.save(model.state_dict(), best_model_path)\n","            mlflow.log_artifact(best_model_path)\n","\n","    plot_and_log_curve(train_loss_list, val_loss_list, \"Loss\", \"loss_curve.png\")\n","    plot_and_log_curve(train_acc_list, val_acc_list, \"Accuracy\", \"accuracy_curve.png\")\n","\n","    # Save the full model for reproducibility (architecture + weights)\n","    final_model_path = \"/tmp/final_model\"\n","    mlflow.pytorch.save_model(model, final_model_path)\n","    mlflow.log_artifacts(final_model_path, artifact_path=\"final_model\")\n","    shutil.rmtree(final_model_path)\n","\n","    print(\"Training finished. Best validation F1:\", best_val_f1)\n","    plot_and_log_confusion_matrix(val_labels, val_preds, step=\"final\", label=\"val\")\n"],"metadata":{"id":"ZP4682bJDz77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748887908653,"user_tz":-180,"elapsed":3685747,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"a03a90c8-12a6-49fd-854c-a56e68502ac6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12: train_loss=0.6697, train_acc=0.6151, val_loss=0.6492, val_acc=0.5499, val_f1=0.1573, val_auc=0.9845\n","Epoch 2/12: train_loss=0.6263, train_acc=0.6828, val_loss=0.5946, val_acc=0.8283, val_f1=0.7888, val_auc=0.9965\n","Epoch 3/12: train_loss=0.5726, train_acc=0.8263, val_loss=0.5200, val_acc=0.9380, val_f1=0.9329, val_auc=0.9981\n","Epoch 4/12: train_loss=0.5045, train_acc=0.9087, val_loss=0.4371, val_acc=0.9729, val_f1=0.9718, val_auc=0.9990\n","Epoch 5/12: train_loss=0.4315, train_acc=0.9467, val_loss=0.3560, val_acc=0.9836, val_f1=0.9832, val_auc=0.9991\n","Epoch 6/12: train_loss=0.3667, train_acc=0.9606, val_loss=0.2876, val_acc=0.9893, val_f1=0.9891, val_auc=0.9995\n","Epoch 7/12: train_loss=0.3101, train_acc=0.9634, val_loss=0.2425, val_acc=0.9858, val_f1=0.9854, val_auc=0.9987\n","Epoch 8/12: train_loss=0.2643, train_acc=0.9683, val_loss=0.1950, val_acc=0.9907, val_f1=0.9906, val_auc=0.9996\n","Epoch 9/12: train_loss=0.2248, train_acc=0.9716, val_loss=0.1639, val_acc=0.9907, val_f1=0.9906, val_auc=0.9997\n","Epoch 10/12: train_loss=0.2011, train_acc=0.9736, val_loss=0.1410, val_acc=0.9922, val_f1=0.9920, val_auc=0.9997\n","Epoch 11/12: train_loss=0.1793, train_acc=0.9712, val_loss=0.1283, val_acc=0.9929, val_f1=0.9928, val_auc=0.9995\n","Epoch 12/12: train_loss=0.1597, train_acc=0.9766, val_loss=0.1114, val_acc=0.9900, val_f1=0.9899, val_auc=0.9997\n"]},{"output_type":"stream","name":"stderr","text":["2025/06/02 18:11:25 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"output_type":"stream","name":"stdout","text":["Training finished. Best validation F1: 0.9927641099855282\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(best_model_path))\n","model.eval()\n","\n","test_labels, test_outputs = [], []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        test_outputs.extend(torch.sigmoid(outputs).cpu().numpy())\n","        test_labels.extend(labels.cpu().numpy())\n","\n","test_labels = np.array(test_labels).astype(int).flatten()\n","test_preds = (np.array(test_outputs) > 0.5).astype(int).flatten()"],"metadata":{"id":"_cN7ay5iJckM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n","\n","test_f1 = f1_score(test_labels, test_preds, zero_division=0)\n","test_recall = recall_score(test_labels, test_preds, zero_division=0)\n","test_precision = precision_score(test_labels, test_preds, zero_division=0)\n","test_auc = roc_auc_score(test_labels, np.array(test_outputs)) if len(np.unique(test_labels)) > 1 else float('nan')\n","\n","print(f\"Test F1: {test_f1:.4f}, Test Recall: {test_recall:.4f}, Test Precision: {test_precision:.4f}, Test AUC: {test_auc:.4f}\")"],"metadata":{"id":"JRsFpmEwQaFW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748888214473,"user_tz":-180,"elapsed":26,"user":{"displayName":"Rares Dan Tiago Goia","userId":"01226619030087852117"}},"outputId":"3aab7a62-8ea0-4583-eb8f-3cd8578d2315"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test F1: 0.9863, Test Recall: 0.9804, Test Precision: 0.9924, Test AUC: 0.9992\n"]}]},{"cell_type":"code","source":["mlflow.log_metrics({\n","    \"test_f1\": test_f1,\n","    \"test_recall\": test_recall,\n","    \"test_precision\": test_precision,\n","    \"test_auc\": test_auc\n","})\n","\n","\n","plot_and_log_confusion_matrix(test_labels, test_preds, step=\"final\", label=\"test\")"],"metadata":{"id":"aYyEx8w1Qe_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3kOyohGcZEJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7gjDmFX0kafU"},"execution_count":null,"outputs":[]}]}